## 성능 테스트 시나리오 & 장애 대응 문서

### 1. 성능 테스트 목적
- 어플리케이션의 최대 처리량(Throughput, TPS)을 측정하여 안정성을 평가.
- API의 응답 속도(Latency)를 다양한 지점(p90, p95, avg)에서 측정.
- Peak 상황에서도 서버의 리소스(CPU, Memory, Disk 등) 사용량을 모니터링하여 성능 병목이 발생할 가능성을 평가.
- 결과를 바탕으로 장애 대응 방안을 수립.
- 부하 테스트를 수행하기 위해, 샘플링 방법을 사용하여 자주 호출되거나 부하가 예상되는 API를 대표적으로 선택하여 테스트를 진행했다.

### 2. 성능 테스트 평가 지점
- TPS (Transactions per Second, 또는 RPS - Requests per Second): 시스템이 초당 처리할 수 있는 최대 요청 수.
- Latency (응답 지연 시간): API 응답 속도. 다음과 같은 통계치를 고려:
   ```
   p50 (중간값): 50%의 요청이 이 시간 이하에서 처리됨.
   p70: 70%의 요청이 이 시간 이하에서 처리됨.
   p90: 90%의 요청이 이 시간 이하에서 처리됨.
   p95: 95%의 요청이 이 시간 이하에서 처리됨.
   p99: 99%의 요청이 이 시간 이하에서 처리됨.
   avg: 평균 응답 시간.
   CPU 사용량: CPU 사용량이 얼마나 증가하는지 확인. 80% 이상 지속될 경우 병목 발생 가능.
   Memory 사용량: 메모리 사용률, 메모리 누수 여부(OOM Killer 작동 여부 포함).
   Disk 사용량 (로그 포함): 디스크 IO와 로그로 인해 발생하는 병목 확인.
   ```
### 3. 성능 테스트 시나리오 단계
1) Baseline 테스트: 최소 트래픽으로 시스템이 정상 동작하는지 확인.
   ![1. base.png](document%2F%EC%84%B1%EB%8A%A5%ED%85%8C%EC%8A%A4%ED%8A%B8%2F1.%20base.png)

   ```
   - 테스트 개요
   테스트 도구: k6
   테스트 기간: 10초
   가상 사용자 수: 최대 100명
   트래픽 패턴: 초당 10개의 요청 (constant request rate)
   목표 TPS: 10~20
   실제 TPS: 10.07

   - 테스트 결과 요약
   초당 요청 수 (TPS): 10.07
   평균 응답 시간: 31.8ms
   최소 응답 시간: 22.59ms
   최대 응답 시간: 61.36ms
   95th Percentile 응답 시간: 52.12ms
   90th Percentile 응답 시간: 47.37ms
   응답 실패율: 0.00% (모든 요청 성공)
   
   - 평가: 테스트 결과, 시스템은 초당 10.07개의 요청을 처리하며 목표 TPS 범위 내에 있다. 최소 트래픽 조건에서도 시스템이 안정적으로 요청을 처리할 수 있음을 나타냄.
   ```
3) 부하 증가 테스트: 트래픽을 점진적으로 증가시켜 최대 처리 용량을 측정.

![2. 부하 tps 100.png](document%2F%EC%84%B1%EB%8A%A5%ED%85%8C%EC%8A%A4%ED%8A%B8%2F2.%20%EB%B6%80%ED%95%98%20tps%20100.png)


![2. 부하 tps 200 > 100.png](document%2F%EC%84%B1%EB%8A%A5%ED%85%8C%EC%8A%A4%ED%8A%B8%2F2.%20%EB%B6%80%ED%95%98%20tps%20200%20%3E%20100.png)

   ```
       - 테스트 개요
      테스트 도구: k6
      테스트 기간: 10초
      가상 사용자 수: 최대 1000명, 최대 2000명
      트래픽 패턴: 초당 100/200개의 요청 (constant request rate)
      트래픽을 100 TPS에서 200 TPS로 점진적으로 증가시키면서 시스템의 최대 처리 용량을 측정.
      목표 TPS: 100
      실제 TPS: 99.69~107.42

       - 테스트 결과 요약
      시나리오 1: 평균 응답 시간 0.1초
      시나리오 2: 평균 응답 시간 8초

      - 평가
      응답 시간이 점진적인 트래픽 증가에 따라 급격히 증가하는 것은 시스템의 처리 용량 한계를 초과했음을 시사.
      TPS가 두 배로 증가함에 따라 응답 시간이 비례하여 증가하지 않고 급격하게 상승. 이는 트래픽이 시스템의 처리 능력을 초과할 때 성능 저하가 비선형적으로 증가함을 보여줌.

      - 성능 저하 원인
      자원 병목: 높은 TPS에 도달했을 때 CPU, 메모리, Disk I/O 등의 자원 병목이 발생했을 가능성이 있다. 자원 부족이 응답 시간 증가의 주된 원인일 수 있다.
         (톰캣은 내부적으로 스레드 풀을 사용하여 요청을 처리합니다. 기본 스레드 풀 크기가 부족하면, 새 요청은 기존 요청이 처리될 때까지 대기하게 됩니다. 트래픽 증가나 긴 작업 수행 시 스레드 풀이 가득 차서 대기 상태가 될 수 있다)
      서버 처리 한계: 서버의 처리 용량이 한계에 도달하면서 요청을 처리하는 데 시간이 지연되었을 수 있다.
      
   ```

3) Peak 테스트 (최고 부하 테스트): 예상 가능한 최대 부하 이상의 트래픽을 가하여 시스템이 어떻게 반응하는지 확인.

![3. peak.png](document%2F%EC%84%B1%EB%8A%A5%ED%85%8C%EC%8A%A4%ED%8A%B8%2F3.%20peak.png)

   ```
      - 테스트 개요
      테스트 기간: 60초
      가상 사용자 수: 최대 3000명
      트래픽 패턴: 초당 300개의 요청 (constant request rate)
      목표 TPS: 300
      실제 TPS: 112

      - 테스트 결과 요약
      초당 요청 수 (TPS): 112
      평균 응답 시간: 20.31s
      최소 응답 시간: 54ms
      최대 응답 시간: 29.72s
      95th Percentile 응답 시간: 27.87ms
      90th Percentile 응답 시간: 27.35ms
      응답 실패율: 0.00% (모든 요청 성공)
      
      - 평가: 
      실제 TPS가 목표 TPS 300에 비해 현저히 낮다. 이는 시스템이 기대된 트래픽 처리 능력을 충족하지 못하고 있음.
      가상 사용자 수를 3000명으로 설정했지만, 실제 요청 처리량이 낮아 시스템의 스케일링 능력에 문제가 있음.
   ```

### 4. 결과 분석 및 평가
4.1) 허용 가능한 응답 시간

   ```
   목표: 응답 시간 1초
   결과:
      Baseline 테스트: 평균 응답 시간 31.8ms로 허용 범위 내
      부하 증가 테스트: 평균 응답 시간이 0.1초에서 8초로 급격히 증가
      Peak 테스트: 평균 응답 시간이 20.31초로 허용 범위를 초과
   ```

4.2) 결론
   ```
   Baseline 테스트에서는 시스템이 낮은 트래픽 조건에서 안정적으로 작동하고, 응답 시간이 허용 범위 내에 있다.
   부하 증가 테스트에서는 응답 시간이 트래픽 증가에 따라 급격히 상승하며 시스템의 처리 용량 한계를 초과했음을 나타냄.
   Peak 테스트에서는 시스템이 높은 부하에서 극심한 성능 저하를 겪으며 응답 시간이 허용 범위를 크게 초과. 이는 시스템이 최대 부하를 초과했을 때 응답 시간이 비정상적으로 길어지는 것을 의미함.
   ```

### 5. 가상 장애 대응 문서
장애 발생 개요
   ```
   장애 발생 일시: 2024-08-21 14:00
   장애 종료 일시: 2024-08-21 14:45
   장애 지속 시간: 45분
   장애 영향 범위: 서비스 지연, API 호출 실패, 사용자 데이터 처리 지연
   ```
장애 원인 분석
   ```
   원인: 과부하 및 메모리 누수
   증상:
      평균 응답 시간: 25초로 증가 (기존 3초)
      API 실패율: 12% (기존 0%)
      OOM(Out of Memory) 오류 발생
      CPU 사용량: 95% 이상으로 급격히 상승
      메모리 사용량: 90% 이상으로 급증
   시스템 로그 분석:
      에러 로그: java.lang.OutOfMemoryError: Java heap space, java.util.concurrent.TimeoutException
      메모리 덤프 분석: 메모리 누수가 발생하고 있으며, 스레드 풀의 대기 상태가 빈번히 발생함을 확인
      성능 모니터링 로그: 높은 CPU 사용량, 메모리 사용량 급증 및 스레드 풀 대기 상태 기록
   ```
대응 과정
   ```
   초동 조치:
      서버 재시작: 14:05에 서버를 재시작하여 메모리 상태를 초기화
      트래픽 분산: 로드 밸런서를 통해 트래픽을 다른 서버로 분산
      임시 패치: 메모리 누수를 방지하기 위한 임시 코드 패치 적용
   추가 대응:
      로그 분석: 자세한 로그 분석을 통해 원인 규명 작업 진행
      원인 확인: 메모리 누수와 과부하의 원인을 확인하기 위해 코드 및 아키텍처 검토
      긴급 수정 작업: 메모리 누수 문제를 해결하기 위한 긴급 코드 수정 및 성능 개선 작업 수행
   ```
재발 방지 대책
   ```
   단기 (Short-Term) 대책:
      서버 자원 증설: CPU 및 메모리 자원 증설을 통해 즉각적인 성능 개선
      임시 패치: 메모리 누수를 방지하기 위한 코드 수정 및 패치
      장애 감지 모니터링 강화: 장애 발생 시 조기 감지를 위한 모니터링 설정 강화
   중기 (Mid-Term) 대책:
      코드 최적화: 메모리 사용 최적화를 위한 코드 리뷰 및 개선
      API 구조 개선: API 호출의 효율성을 높이기 위한 구조 개선 및 최적화
      캐싱 적용: 자주 조회되는 데이터를 캐시하여 서버 부하 감소
   장기 (Long-Term) 대책:
      아키텍처 개선: 시스템 아키텍처를 개선하여 트래픽 부하를 효율적으로 처리할 수 있는 구조로 전환
      트래픽 분산 전략 도입: 분산 처리 및 로드 밸런싱 전략을 도입하여 부하를 균등하게 분산
      리소스 자동 확장 기능 도입: 클라우드 기반의 자동 확장 기능을 도입하여 트래픽에 따라 자원을 자동으로 조절
   ```
향후 계획
   ```
   장애 예방을 위한 모니터링 강화 방안:
      장애 발생을 조기에 감지할 수 있는 모니터링 시스템을 구축
      성능 지표 및 자원 사용량 모니터링을 강화하여 문제 발생 시 즉각 대응
   주기적인 성능 테스트 계획:
      정기적인 부하 테스트 및 성능 테스트를 통해 시스템의 한계 및 개선점을 식별
      테스트 결과를 바탕으로 성능 최적화 및 자원 조정을 수행
   장애 발생 시 대응 체계 개선:
      장애 대응 프로세스를 문서화하고, 팀원들에게 교육 실시
      장애 대응 절차 및 체크리스트를 업데이트하여 빠르고 정확한 대응을 지원
   ```
  
